---
slug: between_two_ferns
title: Interoperability
authors: [njl]
tags: [blog, ml, embedding_models,]
---

We monetize on running the server for private re-training? Private Models? (does it matter)? Or in exchange for DP, we get anonymized data sets back for training?

<!-- truncate -->
<!--
 Distributed Training
 Private LLMs

-->
#### How do those flowers federated learning folks fit in?
